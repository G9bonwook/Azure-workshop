<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <title>Azure OpenAI ê¸°ë°˜ LangChain ì‹¤ìŠµ í”„ë¡œì íŠ¸</title>
</head>
<body>
  <h1>ğŸš€ Azure OpenAI ê¸°ë°˜ LangChain ì‹¤ìŠµ í”„ë¡œì íŠ¸</h1>
  <p><strong>ê°€ì²œëŒ€í•™êµ SW ì•„ì¹´ë°ë¯¸ 6ê¸°</strong> ì›Œí¬ìˆ ì‹¤ìŠµ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.</p>
  <p>LangChainê³¼ Azure OpenAIë¥¼ í™œìš©í•´ ë¬¸ì„œ ì²˜ë¦¬, ìì—°ì–´ ì‘ë‹µ, ì´ë¯¸ì§€ ìƒì„± ë“± ê³ ê¸‰ AI ê¸°ëŠ¥ì„ ë‹¨ê³„ì ìœ¼ë¡œ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.</p>
  <hr>

  <!-- 01 -->
  <h2>ğŸ“„ 01_loader.py - ë¬¸ì„œ ë¡œë”© ì‹¤ìŠµ</h2>
  <p>PDF, DOCX, CSV ë“± ë‹¤ì–‘í•œ ë¬¸ì„œ í¬ë§·ì„ LangChain ë¬¸ì„œ ë¡œë”ë¥¼ í†µí•´ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.</p>
  <ul>
    <li>PDF: <code>PyPDFLoader</code></li>
    <li>DOCX: <code>Docx2txtLoader</code></li>
    <li>CSV: <code>CSVLoader</code></li>
  </ul>
  <pre><code>
from langchain.document_loaders import PyPDFLoader
loader = PyPDFLoader("sample.pdf")
pages = loader.load_and_split()
print(pages[0].page_content)
  </code></pre>

  <!-- 02 -->
  <h2>ğŸ¤– 02_llm.py - Azure LLM ì—°ë™ ë° ì§ˆë¬¸ ì‘ë‹µ</h2>
  <p>Azure OpenAIì˜ GPT-4o-mini ëª¨ë¸ê³¼ LangChain ì—°ë™ì„ í†µí•´ ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ ì‘ë‹µì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.</p>
  <ul>
    <li>ê¸°ë³¸ ì§ˆì˜ì‘ë‹µ</li>
    <li>ì°½ì˜ì ì¸ ì‹œ ìƒì„±</li>
    <li>ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬</li>
  </ul>
  <pre><code>
from langchain.chat_models import AzureChatOpenAI
llm = AzureChatOpenAI(model_name="dev-gpt-4o-mini")
answer = llm.invoke("ì´ìˆœì‹  ì¥êµ°ì´ ëˆ„êµ¬ë‹ˆ?")
print(answer.content)
  </code></pre>

  <!-- 03 -->
  <h2>ğŸ§  03_template.py - í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿</h2>
  <p>LangChainì˜ <code>PromptTemplate</code>ê³¼ <code>ChatPromptTemplate</code>ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ìš”ì²­ì„ ì •í˜•í™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.</p>
  <ul>
    <li>ë³€ìˆ˜í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±</li>
    <li>í…œí”Œë¦¿ ì‘ë‹µ ì¡°ë¦½ ë° ë””ë²„ê¹… ìš©ì´</li>
  </ul>
  <pre><code>
from langchain.prompts import ChatPromptTemplate
prompt = ChatPromptTemplate.from_template("Tell me a joke about {topic}")
print(prompt.format_prompt(topic="cats").to_string())
  </code></pre>

  <!-- 04 -->
  <h2>ğŸ“š 04_splitter.py - í…ìŠ¤íŠ¸ ë¶„í•  (Tokenizer ê¸°ë°˜)</h2>
  <p>ë¬¸ì„œì˜ ê¸´ ë‚´ìš©ì„ GPT ëª¨ë¸ ê¸°ì¤€ì˜ í† í° ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸° ìœ„í•œ ì‹¤ìŠµì…ë‹ˆë‹¤.</p>
  <ul>
    <li>í† í° ê¸¸ì´ì— ë”°ë¼ ìë™ ë¶„í• </li>
    <li>ì¤‘ë³µ(overlap)ì„ í™œìš©í•´ ì˜ë¯¸ ë³´ì¡´</li>
  </ul>
  <pre><code>
from langchain.text_splitter import RecursiveCharacterTextSplitter
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)
chunks = splitter.split_documents(pages)
  </code></pre>

  <!-- 05 -->
  <h2>ğŸ§¬ 05_embedding.py - Azure ê¸°ë°˜ ë¬¸ì„œ ì„ë² ë”©</h2>
  <p>Azure OpenAIì˜ <code>text-embedding-3-small</code> ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ë²¡í„°í™”í•©ë‹ˆë‹¤.</p>
  <pre><code>
from langchain.embeddings import AzureOpenAIEmbeddings
embedding_model = AzureOpenAIEmbeddings(model="dev-text-embedding-3-small")
vectors = embedding_model.embed_documents([chunk.page_content for chunk in docs])
  </code></pre>

  <!-- 06 -->
  <h2>ğŸ—‚ï¸ 06_vector_store.py - ë²¡í„° ì €ì¥ ë° ê²€ìƒ‰</h2>
  <p>ë¬¸ì„œë¥¼ ë²¡í„°í™”í•œ í›„, <strong>Chroma DB</strong>ì— ì €ì¥í•˜ê³  ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.</p>
  <ul>
    <li>ë²¡í„° ì €ì¥: <code>Chroma.from_documents()</code></li>
    <li>ê²€ìƒ‰: <code>similarity_search</code>, <code>similarity_search_with_relevance_scores</code></li>
  </ul>
  <pre><code>
from langchain.vectorstores import Chroma
db = Chroma.from_documents(docs, embeddings)
results = db.similarity_search("íƒ„ì†Œì¤‘ë¦½ì´ ë­ì•¼?")
print(results[0].page_content)
  </code></pre>

  <!-- 07 -->
  <h2>ğŸ“‘ 07_paper_review.py - ë…¼ë¬¸ ë¦¬ë·° ìë™í™”</h2>
  <p>LLMê³¼ Prompt Templateì„ ì´ìš©í•˜ì—¬ ë…¼ë¬¸ ë‚´ìš©ì„ ìš”ì•½í•˜ê³ , ê°•ì /í•œê³„ì  ë¶„ì„, í‰ì  ë§¤ê¸°ê¸°ê¹Œì§€ ìˆ˜í–‰í•©ë‹ˆë‹¤.</p>
  <pre><code>
template = """
ë„ˆëŠ” ë…¼ë¬¸ ë¦¬ë·°ì–´ì•¼. ë‹¤ìŒ ë…¼ë¬¸ ë‚´ìš©ì„ ë³´ê³  ì•„ë˜ë¥¼ ìˆ˜í–‰í•´ì¤˜:
1. ì—°êµ¬ ëª©ì  ìš”ì•½
2. ê°•ì ê³¼ í•œê³„ ì •ë¦¬
3. í‰ì  ë¶€ì—¬ (5ì  ê¸°ì¤€)
ë…¼ë¬¸ ë‚´ìš©: {context}
"""
  </code></pre>

  <!-- PROJECT -->
  <h2>ğŸ¨ project.py - AI ë„¤ ì»· ë§Œí™” ìƒì„±ê¸°</h2>
  <p><strong>DALLÂ·E 3 + GPT-4o-mini</strong>ë¥¼ ì¡°í•©í•˜ì—¬ ì‚¬ìš©ìì˜ ì£¼ì œë¡œ 4ì»· ë§Œí™”ë¥¼ ìë™ ìƒì„±í•˜ëŠ” í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.</p>
  <ul>
    <li>ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì…ë ¥</li>
    <li>GPTê°€ ì»·ë³„ ìŠ¤í† ë¦¬ ìƒì„±</li>
    <li>DALLÂ·Eë¡œ ê° ì»· ì´ë¯¸ì§€ë¥¼ ìƒì„±</li>
    <li>ì „ì²´ ë§Œí™”ë¥¼ ì´ì–´ë¶™ì—¬ ìŠ¤í† ë¦¬ ì™„ì„±</li>
  </ul>
  <pre><code>
# 1. ìœ ì € í”„ë¡¬í”„íŠ¸ ìˆ˜ì§‘ â†’ ì»·ë³„ ìŠ¤í† ë¦¬ ì‘ì„±
# 2. GPTê°€ ì»·ë³„ ë¬˜ì‚¬ ìƒì„± â†’ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„±
# 3. DALL-Eë¡œ ì´ë¯¸ì§€ 4ì¥ ìƒì„±
# 4. ë„¤ ì¥ì˜ ì´ë¯¸ì§€ë¥¼ í•œ ì¥ìœ¼ë¡œ í•©ì„±
  </code></pre>

  <hr>
  <h2>âœ… ì¢…í•© ì •ë¦¬</h2>
  <ol>
    <li>ë¬¸ì„œ ë¡œë“œ â†’ í…ìŠ¤íŠ¸ ë¶„í• </li>
    <li>ë¬¸ì„œ ì„ë² ë”© â†’ ë²¡í„° ì €ì¥</li>
    <li>ìœ ì‚¬ë„ ê²€ìƒ‰ â†’ LLMìœ¼ë¡œ ì‘ë‹µ ìƒì„±</li>
    <li>LLMì˜ ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ í™œìš© â†’ ë¦¬ë·°, ìš”ì•½, ìƒì„±</li>
    <li>AI ìƒì„± ê¸°ìˆ (DALLÂ·E) ì—°ë™ â†’ ì‹œê°ì  ìŠ¤í† ë¦¬ ì œì‘</li>
  </ol>

  <p><em>ë³¸ ì›Œí¬ìˆì€ ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì‘ìš© ê°€ëŠ¥í•œ AI ê¸°ìˆ ì„ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì„±ë˜ì—ˆìœ¼ë©°, ëª¨ë“  ì½”ë“œëŠ” LangChain + Azure ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.</em></p>
</body>
</html>
