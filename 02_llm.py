# -*- coding: utf-8 -*-
"""02-LLM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zXnCqPNpjnIynALrt9vJdSSVv0HEZErw
"""

!pip install langchain langchain-core langchain-community
!pip install openai

import os

os.environ["OPENAI_API_KEY"] = "FqS58pSUL1NvngffvVvxvYpwLm92Z3YotUc6LDgTPexWG7cSXEH1JQQJ99BDACfhMk5XJ3w3AAABACOGsB69"
os.environ["AZURE_OPENAI_ENDPOINT"] = "https://gacheon-llm-001.openai.azure.com"
os.environ["OPENAI_API_TYPE"] = "azure"
os.environ["OPENAI_API_VERSION"] = "2023-05-15"

from langchain.chat_models import AzureChatOpenAI

llm = AzureChatOpenAI(model_name="dev-gpt-4o-mini")
answer = llm.invoke("이순신 장군이 누구니?")

print(answer.content)

llm = AzureChatOpenAI(model_name="dev-gpt-4o-mini",
                      temperature=1)
answer = llm.invoke("가천대의 흐트러진 벗꽃을 주제로 청춘과 낭만에 대한 시를 지어줘 ?")

print(answer.content)

from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

llm = AzureChatOpenAI(
    model_name="dev-gpt-4o-mini",
    streaming=True,
    callbacks=[StreamingStdOutCallbackHandler()],
    temperature=1,
    max_tokens=1000
)

answer = llm.invoke("가천대의 흐트러진 벗꽃을 주제로 청춘과 낭만에 대한 시를 지어줘 ?")

